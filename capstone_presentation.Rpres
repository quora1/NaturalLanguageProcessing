Next Word Prediction
========================================================
author: Wiktoria Urantowka
date: 08.04.2018
font-family: 'Helvetica'
css: custom.css
autosize: true
<small>Capstone Project   
Data Science Specialization   
John Hopkins University</small>
```{r}

```

Overview:
========================================================

<small>Capstone Project finalizes 9-course Data Science Specialization and it's purpose is to built a Shiny application predicting words based on the last n-number of words input by the user.


--> The tool is available here:
[WordPredictorTool](https://quora1.shinyapps.io/WordPredictor_Final/) 

--> The data used to train the algorith is available here: [Data](https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip)


Building of the word-predicting-tool consisted of 3 steps: 

-Pre-processing the data  
-Computation of n-grams  
-Setting up a function that uses n-grams to predict next word 

The following slides will provide more detail on each of the step</small>





Pre-processing 
========================================================
1. Creation of a sample corpus from 3 data sources: Blogs, News and Twitter

2. Transforming it by:  
<small><small> 
 -Removing all characters not standard in English language   
 -Removing punctuations  
 -Removing numbers   
 -Removing stopwords limited number of stopwords ("a" and "the")  
 -Removing additional interword space  
 -Converting words to lower case   
 -Stemming words ( Grouping words of the same meaning together ex "run", "ran", "running")</small></small>

3. Tokenizing the corpus (defining that words are separate units of the text)


 Creating n-grams
========================================================

Computation of frequency files (series of the most frequent combinations of 2, 3 and 4 words)
Example of the most frequent 4grams

```{r, echo=FALSE}
setwd("/Users/quora1/Desktop/DataScience/10_Capstone/final/en_US")
ngramFour<-readRDS("./ngramFour.rds")
rownames(ngramFour) <- NULL
head(ngramFour)
```

How it works?
========================================================

Elements necessary for prediction: 

<small><small>
1.  Input provided by the user that gets fed into a function that preprocesses it 
    and subsets the last 3 words from the sentence (in case the input is longet than 3 words)   
2.  The n-gram files ordered in descending order according to their 
    frequency of occurance in corpora.   </small></small>
    
Prediction Procedure:   

<small><small>The prediction function grams the words input by the user and matches it with the most frequent ngrams:
If the input contains 3 words, they are matched with 4 grams, if 2 words with 3 grams, if 1 word with 2 grams
The procedure is always started by the highest possible order of ngrams  and if no match is found, it tries to find a match within a lower ngram order. In case there is more than one match, the one with the highest frequency is applied
</small></small>


